# ðŸ¤– AI Interview Coach  
*A self-hosted, intelligent mock interview partner.*  

This project is an **interactive AI interview coach** designed to simulate realistic technical interviews. It generates **role-specific questions**, evaluates user responses, and provides **structured feedback** â€” helping candidates prepare for interviews with a hands-on, conversational approach.  

The system combines a **locally-hosted LLM** with **workflow automation** for a scalable and flexible architecture.  

---

## âœ¨ Key Features  

- ðŸŽ¯ **Role-Specific Questions**  
  Generate realistic interview questions tailored to roles like *Cloud Security, DevOps, or Software Engineering*.  

- ðŸ“ **Structured Feedback**  
  Get detailed analysis of your answers, covering *clarity, correctness, and conciseness*, along with scoring.  

- ðŸ”„ **Interactive Mock Interview**  
  Works like a real interview loop â€” new questions and follow-ups are asked dynamically.  

- ðŸ§© **Decoupled Architecture**  
  The AI logic (Flask + LLM) and workflow orchestration (n8n) are independent, making it **modular and scalable**.  

---

## ðŸ› ï¸ Technologies Used  

- **[Python 3.9+](https://www.python.org/)** â€“ Core programming language  
- **[Flask](https://flask.palletsprojects.com/)** â€“ Lightweight web server exposing REST API endpoints  
- **[Hugging Face Transformers](https://huggingface.co/transformers/)** â€“ To load and run locally-hosted LLMs  
  - *Models tested*: `bigscience/bloom-560m` and `mistralai/Mistral-7B-Instruct-v0.1`  
- **[PyTorch](https://pytorch.org/)** â€“ Deep learning backend for model inference  
- **[n8n](https://n8n.io/)** â€“ Workflow automation and orchestration engine  
- **[ngrok](https://ngrok.com/)** â€“ Secure tunneling to expose local Flask server to n8n Cloud  
- **Shell & cURL** â€“ For local testing and debugging of webhooks  

---

## âš™ï¸ Architecture Overview 
User (candidate)
â”‚
â”œâ”€â”€> Webhook â†’ n8n Workflow
â”‚ â”‚
â”‚ â”œâ”€â”€> HTTP Request â†’ Local Flask API (/generate)
â”‚ â”‚ â”‚
â”‚ â”‚ â””â”€â”€> Locally-hosted LLM (Bloom / Mistral)
â”‚ â”‚ - Generates interview question OR
â”‚ â”‚ - Evaluates user answer
â”‚ â”‚
â”‚ â””â”€â”€> Respond to Webhook â†’ Returns AI output to user
â”‚
â””â”€â”€> User sends next answer â†’ cycle continues 

--


![Project Architechture](AI-interview-Agent-
/The AI Agent Interview .png)




